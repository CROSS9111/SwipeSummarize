# 機能要件ドキュメント

## 目次

1. [概要](#概要)
2. [機能一覧](#機能一覧)
3. [各機能詳細](#各機能詳細)

---

## 概要

SwipeSummarize は、「後で読む」記事を AI 要約でサクサク消化する Tinder 風 UI の Web アプリケーションです。

### 主要機能カテゴリ

- **コンテンツ管理**: URL 保存、記事抽出、要約生成
- **UI/UX**: スワイプインターフェース、記事カード表示
- **LLM 統合**: 複数プロバイダー対応、自動フォールバック

---

## 機能一覧

| 機能 ID              | 機能名                    | カテゴリ | 優先度 | ステータス |
| -------------------- | ------------------------- | -------- | ------ | ---------- |
| F-001-VERCEL-AI-SDK  | Vercel AI SDK 統合        | LLM 統合 | 高     | 設計完了   |
| F-002-SWIPE-UI       | スワイプインターフェース  | UI/UX    | 高     | 実装済み   |
| F-003-URL-MANAGEMENT | URL 管理                  | コンテンツ | 高     | 実装済み   |
| F-004-SUMMARY-GEN    | AI 要約生成               | コンテンツ | 高     | 実装済み   |
| F-005-TEST-CHAT      | LLMテストチャット         | 開発ツール | 中     | 実装済み   |
| F-006-WAITING-LIST   | Waiting List表示          | UI/UX    | 中     | 実装済み   |

---

## 各機能詳細

### F-001-VERCEL-AI-SDK: Vercel AI SDK 統合機能

#### 概要
Vercel AI SDK を使用して 20+の LLM プロバイダーに対応し、統一的なインターフェースで要約生成を行える機能。

#### ビジネス価値
- 複数の LLM プロバイダーから最適なものを選択可能
- コスト最適化と可用性の向上
- エンタープライズ要件への対応（Azure OpenAI）

#### ユーザーストーリー
- ユーザーとして、複数の LLM プロバイダーから選択して記事要約を生成したい
- ユーザーとして、LLM の使用コストを追跡・確認したい
- ユーザーとして、API レート制限に応じて自動的に別のプロバイダーに切り替えたい
- ユーザーとして、環境に応じた設定を管理したい

#### 対応プロバイダー
- **必須**: Azure OpenAI
- **推奨**: OpenAI, Anthropic (Claude), Google (Gemini)
- **オプション**: AWS Bedrock, Google Vertex AI, xAI Grok, Ollama (ローカル)

#### 主要機能
1. **統一 API インターフェース**
   - 全プロバイダー共通の API
   - ストリーミング対応
   - トークン使用量追跡

2. **プロバイダー管理**
   - 環境別設定（開発/ステージング/本番）
   - API キーの暗号化保存
   - 接続テスト機能

3. **コスト管理**
   - リアルタイムコスト計算
   - 月間使用量レポート
   - プロバイダー別コスト比較

4. **フォールバック機能**
   - レート制限時の自動切り替え
   - エラー時のリトライ
   - 優先順位設定

#### 技術仕様
- 統一インターフェース: `lib/llm/client.ts`
- API エンドポイント: `/api/llm/*`, `/api/summarize`
- データベース: `llm_settings`, `llm_usage` テーブル
- 暗号化: Supabase Vault 使用

#### 制約事項
- API キーは環境変数または暗号化して DB 保存
- コスト計算は推定値
- 各プロバイダーのレート制限に準拠

#### 関連ドキュメント
- [API 仕様](./api/llm_apis.md)
- [DB スキーマ](./database/schema/llm_tables.sql)
- [テストケース](./testing/llm/)

---

### F-002-SWIPE-UI: スワイプインターフェース

#### 概要
Tinder 風のスワイプ操作で記事を効率的に処理できる UI。

#### 主要機能
- 右スワイプ: 記事を保存
- 左スワイプ: 記事をスキップ
- タップ: 詳細表示
- ジェスチャー対応（モバイル）

---

### F-003-URL-MANAGEMENT: URL 管理

#### 概要
記事 URL の保存、取得、削除を管理する機能。

#### 主要機能
- URL の追加（手動/ブックマークレット）
- 重複チェック
- カテゴリ分類
- アーカイブ機能

---

### F-004-SUMMARY-GEN: AI 要約生成

#### 概要
保存した記事から AI を使用して要約を生成する機能。

#### 主要機能
- Jina Reader API でコンテンツ抽出
- LLM プロバイダーで要約生成
- 3-5 文の簡潔な要約
- 日本語対応

---

### F-005-TEST-CHAT: LLMテストチャット

#### 概要
開発者向けのLLMプロバイダーテスト機能。各プロバイダーのモデルに対して固定プロンプトでテストリクエストを送信し、動作確認とデバッグを行う。

#### ビジネス価値
- LLMプロバイダーの動作確認とデバッグ効率の向上
- 新規プロバイダー追加時の検証作業の簡素化
- APIキーやエンドポイントの設定確認

#### ユーザーストーリー
- 開発者として、各LLMプロバイダーの接続テストを素早く実行したい
- 開発者として、新しいAPIキーが正常に動作することを確認したい
- 開発者として、異なるモデルの応答時間とコストを比較したい

#### 主要機能
- 7つのLLMプロバイダー対応（OpenAI、Anthropic、Google、Azure OpenAI、AWS Bedrock、Vertex AI、Ollama）
- 固定プロンプトでのテスト実行
- レスポンス時間・トークン使用量・コスト表示
- 開発環境限定のセキュリティ制御
- 認証情報の非永続化

---

### F-006-WAITING-LIST: Waiting List表示

#### 概要
トップページ下部に、waiting list（未要約のURLリスト）を一覧表示する機能。要約生成は不要で、ドメイン名＋URLのシンプルなリストとして表示する。

#### ビジネス価値
- ユーザーが待機中の記事を一覧で把握できる
- 記事の優先順位を視覚的に確認可能
- ランダム選択前に全体像を把握できる

#### ユーザーストーリー
- ユーザーとして、待機中の記事リストを確認して、次に読まれる記事の候補を把握したい
- ユーザーとして、特定の記事を直接クリックして元記事を開きたい
- ユーザーとして、大量の待機記事がある場合でも、スムーズにスクロールして確認したい

#### 主要機能
1. **無限スクロール表示**
   - 初期20件表示、スクロールで自動読み込み
   - Intersection Observer APIによる効率的な実装
   - useRefパターンによるパフォーマンス最適化

2. **記事リスト表示**
   - ドメイン名とフルURLの表示
   - クリックで元記事を新規タブで開く
   - 作成日時による降順ソート

3. **リアルタイム更新**
   - URL追加時の自動リフレッシュ
   - refreshTriggerによる状態同期
   - 楽観的UIアップデート

#### 技術仕様
- **API**: `/api/urls/waiting-list` (GET)
- **コンポーネント**: `WaitingList.tsx`, `WaitingListItem.tsx`
- **データベース**: `urls`テーブル（既存）
- **パフォーマンス**: useRef + useCallbackによる無限ループ対策

#### 制約事項
- データベーススキーマ制約により、実装時にタイトル表示をドメイン名表示に変更
- 全URLが「待機中」として表示（要約の有無に関わらず）
- モバイルでのタップ領域最適化済み

---

## 今後の機能拡張候補

- タグ機能
- 検索機能
- エクスポート機能
- 共有機能
- ブラウザ拡張機能
- モバイルアプリ