# LLMテストチャット機能 - 統合設計書

**機能ID**: F-005-TEST-CHAT
**作成日**: 2024-12-30
**更新日**: 2024-12-30
**ステータス**: ~~実装済み~~ → Merged (2024-12-30)

> **Note**: This spec has been merged into docs/ on 2024-12-30. Do not edit this file directly.
> 昇格先: docs/functional_requirements.md (F-005追加), docs/api/test_chat_apis.md (新規)

---

## 1. 概要

### 1.1 機能概要
開発者向けのLLMテスト機能。各プロバイダーのモデルに対して固定プロンプトでテストリクエストを送信し、レスポンスと処理時間を確認できる開発ツール。

### 1.2 ビジネス価値
- LLMプロバイダーの動作確認とデバッグ効率の向上
- 新規プロバイダー追加時の検証作業の簡素化
- APIキーやエンドポイントの設定確認
- モデル性能とコストの事前検証

### 1.3 ユーザーストーリー
- **開発者として**、各LLMプロバイダーの接続テストを素早く実行したい
- **開発者として**、新しいAPIキーが正常に動作することを確認したい
- **開発者として**、異なるモデルの応答時間とコストを比較したい
- **開発者として**、エラー時の詳細情報を確認してデバッグを効率化したい

---

## 2. API設計

### 2.1 エンドポイント一覧

| Method | Path | 説明 | 認証 |
|--------|------|------|------|
| POST | `/api/admin/llm-test` | LLMテスト実行 | なし（開発環境限定） |

### 2.2 API詳細仕様

#### 2.2.1 POST `/api/admin/llm-test`

**概要**: LLMプロバイダーに対してテストリクエストを送信

**リクエスト**:
```typescript
{
  provider: ProviderId;           // 必須
  model: string;                  // 必須
  apiKey?: string;                // プロバイダー依存
  endpoint?: string;              // プロバイダー依存
  deploymentName?: string;        // Azure OpenAI用
  apiVersion?: string;            // Azure OpenAI用
  region?: string;                // AWS Bedrock用
  accessKeyId?: string;           // AWS Bedrock用
  secretAccessKey?: string;       // AWS Bedrock用
  projectId?: string;             // Vertex AI用
  location?: string;              // Vertex AI用
  maxTokens?: number;             // デフォルト: 1000
  temperature?: number;           // デフォルト: 0.7
}
```

**レスポンス（成功時）**:
```typescript
{
  success: true;
  response: string;               // LLMからのレスポンス
  processingTime: number;         // 処理時間（ms）
  provider: string;               // 使用プロバイダー
  model: string;                  // 使用モデル
  usage: {
    inputTokens: number;
    outputTokens: number;
    totalTokens: number;
    estimatedCost: number;        // USD
  };
}
```

**レスポンス（エラー時）**:
```typescript
{
  success: false;
  error: string;                  // エラーメッセージ
  processingTime: number;         // エラーまでの処理時間
  provider: string;
  model: string;
  details?: unknown;              // エラー詳細
}
```

---

## 3. データモデル・バリデーション

### 3.1 リクエストパラメータ詳細

| 項目名 | 型 | 必須 | 制約ルール | 備考 |
|--------|-----|------|-----------|------|
| provider | string | ✅ | PROVIDERS配列のid値 | プロバイダーID |
| model | string | ✅ | 選択プロバイダーのmodels配列の値 | モデル名 |
| apiKey | string | ※ | 1文字以上 | プロバイダー依存 |
| endpoint | string | - | URL形式 | Azure OpenAI等 |
| deploymentName | string | ※ | 1文字以上 | Azure OpenAI必須 |
| apiVersion | string | ※ | YYYY-MM-DD形式 | Azure OpenAI必須 |
| region | string | ※ | AWS リージョン名 | AWS Bedrock必須 |
| accessKeyId | string | ※ | AKIA形式 | AWS Bedrock必須 |
| secretAccessKey | string | ※ | 1文字以上 | AWS Bedrock必須 |
| projectId | string | ※ | 1文字以上 | Vertex AI必須 |
| location | string | ※ | GCPロケーション名 | Vertex AI必須 |
| maxTokens | number | - | 100-4000 | デフォルト: 1000 |
| temperature | number | - | 0.0-2.0 | デフォルト: 0.7 |

### 3.2 プロバイダー別必須フィールド

| プロバイダー | 必須フィールド |
|-------------|---------------|
| openai | apiKey |
| anthropic | apiKey |
| google | apiKey |
| azure-openai | apiKey, endpoint, deploymentName, apiVersion |
| aws-bedrock | region, accessKeyId, secretAccessKey |
| vertex-ai | projectId, location |
| ollama | なし |

---

## 4. ロジック・権限設計

### 4.1 認証・認可

* **認証**: 不要
* **認可**: 開発環境限定（NODE_ENV=development）

### 4.2 アクセス制御

| 操作 | 権限ルール |
|------|-----------|
| テスト実行 | 開発環境でのみ許可 |
| 本番環境 | 404 Not Found を返却 |

### 4.3 セキュリティ要件

- APIキー等の認証情報はメモリ上でのみ使用
- データベースへの保存なし
- llm_usageテーブルへの記録なし
- セッション終了時に認証情報は破棄

---

## 5. データベース設計

### 5.1 テーブル設計

**重要**: この機能はデータベースを使用しません。すべてのデータはメモリ上で処理され、永続化されません。

---

## 6. 状態遷移

### 6.1 テスト実行状態

| 状態 | 説明 | 次状態 |
|------|------|--------|
| IDLE | 待機中 | TESTING |
| TESTING | テスト実行中 | SUCCESS / ERROR |
| SUCCESS | テスト成功 | IDLE |
| ERROR | テスト失敗 | IDLE |

### 6.2 UI状態管理

```typescript
interface TestState {
  loading: boolean;
  result: TestResult | null;
  config: TestConfig;
}
```

---

## 7. フロントエンド設計

### 7.1 コンポーネント構成

```
TestChatPage
├── TestInterface          # 設定フォーム
│   ├── ProviderSelector   # プロバイダー選択
│   ├── ModelSelector      # モデル選択
│   ├── ConfigFields       # 認証情報入力
│   └── TestButton         # 実行ボタン
└── TestResults            # 結果表示
    ├── SuccessDisplay     # 成功時の表示
    └── ErrorDisplay       # エラー時の表示
```

### 7.2 状態管理

- **ローカル状態**: React useState
- **フォーム管理**: 自前実装（React Hook Form不使用）
- **エラーハンドリング**: try-catch + toast通知

### 7.3 UI仕様

#### レイアウト
- **2カラムレイアウト**: 左側設定、右側結果
- **レスポンシブ**: モバイルでは1カラム
- **shadcn/ui**: 既存デザインシステム準拠

#### インタラクション
- **リアルタイム検証**: フォーム入力時の即座な検証
- **プロバイダー連動**: プロバイダー選択時にモデル選択肢を更新
- **結果表示**: コピーボタン付きのコードブロック

---

## 8. エラーハンドリング

### 8.1 エラー分類

| エラータイプ | HTTPステータス | メッセージ例 | 対処法 |
|-------------|--------------|-------------|--------|
| バリデーション | 400 | "プロバイダーとモデルは必須です" | 入力チェック |
| 認証エラー | 400 | "APIキーが必要です" | 認証情報確認 |
| LLM実行エラー | 200 | "Invalid API key provided" | プロバイダー側エラー |
| 環境制限 | 404 | "This feature is only available in development" | 環境確認 |
| サーバーエラー | 500 | "サーバーエラーが発生しました" | ログ確認 |

### 8.2 エラー処理フロー

```typescript
try {
  // LLM実行
  const result = await llmClient.summarize(PROMPT);
  return { success: true, ...result };
} catch (llmError) {
  return {
    success: false,
    error: llmError.message,
    details: llmError.stack
  };
}
```

---

## 9. テストケース

### 9.1 ユースケース & テストシナリオ

| ID | シナリオ概要 | アクター | 前提条件 | 操作手順 / 入力データ | 期待される挙動 / レスポンス | 検証すべき副作用 |
|----|------------|---------|---------|---------------------|---------------------------|-----------------|
| UC-01 | [正常系] OpenAI GPT-4oテスト | 開発者 | 有効なAPIキー | 1. プロバイダー: "openai"<br>2. モデル: "gpt-4o"<br>3. APIキー入力<br>4. テスト実行 | ・200 OK<br>・success: true<br>・レスポンステキスト表示<br>・処理時間・コスト表示 | なし |
| UC-02 | [正常系] Anthropic Claudeテスト | 開発者 | 有効なAPIキー | 1. プロバイダー: "anthropic"<br>2. モデル: "claude-3-5-haiku-latest"<br>3. APIキー入力<br>4. テスト実行 | ・200 OK<br>・success: true<br>・レスポンステキスト表示 | なし |
| UC-03 | [正常系] Azure OpenAIテスト | 開発者 | 有効な設定情報 | 1. プロバイダー: "azure-openai"<br>2. 全必須フィールド入力<br>3. テスト実行 | ・200 OK<br>・success: true<br>・レスポンステキスト表示 | なし |
| UC-04 | [異常系] 無効なAPIキー | 開発者 | - | 1. プロバイダー選択<br>2. 無効なAPIキー入力<br>3. テスト実行 | ・200 OK<br>・success: false<br>・"Invalid API key"エラー表示 | なし |
| UC-05 | [異常系] 必須フィールド不足 | 開発者 | - | 1. プロバイダー: "azure-openai"<br>2. APIキーのみ入力<br>3. テスト実行 | ・400 Bad Request<br>・"必須設定が不足"エラー | なし |
| UC-06 | [異常系] 本番環境アクセス | 開発者 | NODE_ENV=production | 1. エンドポイントアクセス | ・404 Not Found<br>・"development only"メッセージ | なし |
| UC-07 | [境界値] 最大トークン数テスト | 開発者 | 有効なAPIキー | 1. maxTokens: 4000設定<br>2. テスト実行 | ・正常実行<br>・長文レスポンス取得 | なし |
| UC-08 | [境界値] 高いTemperatureテスト | 開発者 | 有効なAPIキー | 1. temperature: 2.0設定<br>2. テスト実行 | ・正常実行<br>・創造的なレスポンス | なし |

---

## 10. 実装メモ

### 10.1 技術決定事項

- **固定プロンプト**: "Hello! Please introduce yourself and explain your capabilities in 2-3 sentences."
- **環境制限**: `process.env.NODE_ENV === "development"` でチェック
- **UIライブラリ**: shadcn/ui（Alert、Card、Button等）
- **状態管理**: ローカル状態のみ使用
- **エラーハンドリング**: 既存LLMClientのエラー処理を流用

### 10.2 実装上の注意点

- LLMClientの既存実装をそのまま利用
- APIキーの永続化は絶対に行わない
- 本番環境での誤実行を防ぐため、複数箇所で環境チェック
- プロバイダー固有フィールドの動的表示

### 10.3 今後の拡張予定

- カスタムプロンプト機能
- 複数モデルの同時比較
- テスト履歴の一時保存（セッション内）
- レスポンス時間のベンチマーク機能

---

## 11. 昇格チェックリスト

### 11.1 昇格先確認

| セクション | 昇格先ドキュメント | 昇格状況 |
|-----------|-------------------|----------|
| 1. 概要 | `docs/functional_requirements.md` (F-005追加) | ✅ 完了 |
| 2. API設計 | `docs/api/test_chat_apis.md` | ✅ 完了 |
| 7. フロントエンド設計 | `docs/design/detailed_design/frontend/` | - |
| 8. エラーハンドリング | `docs/design/service_layer_design.md` | - |
| 9. テストケース | `docs/testing/` | - |

### 11.2 品質チェック

- [x] TypeScript型チェック合格
- [x] ESLint合格（新規ファイルのみ）
- [x] 単体テスト実装（手動テスト済み）
- [x] セキュリティチェック（認証情報非永続化）
- [x] 開発環境制限の動作確認

---

## 12. 関連ドキュメント

- [機能要件](/docs/functional_requirements.md) - F-005-TEST-CHAT
- [LLMクライアント実装](/lib/llm/client.ts)
- [プロバイダー定義](/lib/llm/providers.ts)
- [LLM管理API](/docs/api/llm-admin-apis.md)